{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing_data.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbWMEWiBqDDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d661c860-b7aa-4cb4-bb03-fb01e340cfc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab에 Mecab 설치\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "id": "9ZfM_Hmq_m6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 import\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "# text preprocessing\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "# Bio preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Wav preprocessing\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pickle\n",
        "import sklearn\n",
        "from sklearn.preprocessing import scale"
      ],
      "metadata": {
        "id": "U1i5oETuq4tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/Human_understand/KEMDy19"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEkmPOkejR2X",
        "outputId": "27809408-d2b9-4392-9bec-d2d14303b480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Human_understand/KEMDy19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label\n",
        "#Annotation 폴더 내 cvs에서 label 데이터 추출"
      ],
      "metadata": {
        "id": "5Om5LLLkup_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annotation = '/content/gdrive/MyDrive/Human_understand/KEMDy19/annotation/*.csv'\n",
        "folders = glob.glob(annotation)\n",
        "df_all_label = pd.DataFrame()\n",
        "\n",
        "for files in folders:\n",
        "    Label = pd.read_csv(files, usecols=[9, 10])\n",
        "    df_all_label = pd.concat([df_all_label, Label])\n",
        "\n",
        "df_all_label.rename(columns={'Segment ID':'Seg', 'Total Evaluation':'Label'}, inplace=True)\n",
        "df_all_label = df_all_label.drop([0])\n",
        "print('df_all_label', df_all_label)\n",
        "print('==============Label 데이터 추출완료==============')\n",
        "\n",
        "# Lable csv 파일로 저장\n",
        "df_all_label.to_csv(\"df_label.csv\", mode='w')\n",
        "print('==============Label 데이터 저장완료==============')"
      ],
      "metadata": {
        "id": "87PEqYIsu7G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장한 Label csv파일 read\n",
        "label= pd.read_csv('Your_dataset_path/Human_understand/KEMDy19/df_label.csv')\n",
        "\n",
        "# 감정 레이블에 ;(세미콜론)있는 경우 앞의 감정을 추출하는 함수 정의\n",
        "def delSemi(x):\n",
        "  if \";\" in x:\n",
        "    idx_number = x.find(\";\")\n",
        "    return x[:idx_number]\n",
        "  else:\n",
        "    return x\n",
        "\n",
        "# label 컬럼에 apply함수를 적용\n",
        "label['Label'] = label['Label'].apply(lambda x:delSemi(x))\n",
        "print('label', label)\n",
        "\n",
        "# Lable csv 파일로 저장 (세미콜론 앞의 감정이 추출된 Label 파일)\n",
        "label.to_csv(\"df_all_label.csv\", mode='w')\n",
        "print('==============Label데이터 cav파일로 저장완료==============')"
      ],
      "metadata": {
        "id": "23BxtI3e6OI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEXT\n",
        "# 폴더 내에 있는 .txt 파일만 읽고 하나의 .txt파일에 입력하기"
      ],
      "metadata": {
        "id": "2sAQ_a5xrfGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 해당 부분은 코랩에서 실행시 순서대로 파일들을 읽어오지 않아 Segment ID가 랜덤으로 작성될 우려가 있으므로\n",
        "# preprocessing_data.py를 이용하여 해당 부분만 실행시킬 것을 권장드림\n",
        "\n",
        "# targetPattern = '/content/gdrive/MyDrive/Human_understand/KEMDy19/wav/**/**/*.txt'\n",
        "allTextFile = glob.glob(targetPattern)\n",
        "\n",
        "# merged_seg_text.txt파일에 raw text 입력\n",
        "mergedText = open('merged_seg_text.txt', 'w', encoding=\"UTF-8\")\n",
        "for i in range(len(allTextFile)):\n",
        "    myText = allTextFile[i]\n",
        "    first = myText.rfind('Sess')\n",
        "    last = myText.find('.txt')\n",
        "    sessID = myText[first:last]\n",
        "    myText = open(myText, 'r', encoding=\"UTF-8\")\n",
        "    text = sessID + ',' + myText.readline()\n",
        "    mergedText.write(text)\n",
        "mergedText.close()\n",
        "print('==============Text 데이터 추출완료==============')"
      ],
      "metadata": {
        "id": "sC2Kp6qtrA_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "text 데이터와 label 데이터와 병합 후 각 row에 중복되는 값 제거"
      ],
      "metadata": {
        "id": "78VR76O38lhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_text = pd.read_csv('/content/gdrive/MyDrive/Human_understand/KEMDy19/merged_seg_text.txt', names=['Seg', 'text'])\n",
        "label = pd.read_csv('/content/gdrive/MyDrive/Human_understand/KEMDy19/df_all_label.csv', names=['Seg', 'Label'])\n",
        "\n",
        "# text와 label 데이터를 Segment ID를 기준으로 병합하기\n",
        "df_all_txt_label = pd.merge(label, df_all_text, on='Seg')\n",
        "\n",
        "# 정규 표현식을 사용하여 한글을 제외한 단어 제거 및 공백 제거하기\n",
        "df_all_txt_label['text'] = df_all_txt_label['text'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "df_all_txt_label['text'].replace('', np.nan, inplace=True)\n",
        "df_all_txt_label = df_all_txt_label.dropna(how='any')\n",
        "\n",
        "# 각 컬럼에서 중복되는 row 삭제\n",
        "df_all_txt_label['Seg'].nunique(), df_all_txt_label['Label'].nunique(), df_all_txt_label['text'].nunique()\n",
        "df_all_txt_label.drop_duplicates(subset=['Seg'], inplace=True)\n",
        "print('df_all_txt_label', df_all_txt_label)\n",
        "\n",
        "# null 값이 있는지 확인하기\n",
        "print('null값이 있나요?', df_all_txt_label.isnull().values.any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYCMemKd6OGt",
        "outputId": "c8cb54f4-ee71-4c1c-b955-fbb6bb6b516d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        Seg     Label  \\\n",
            "0      Sess01_script01_M001  surprise   \n",
            "2      Sess01_script01_F001      fear   \n",
            "4      Sess01_script01_M002      fear   \n",
            "6      Sess01_script01_M003      fear   \n",
            "8      Sess01_script01_F002      fear   \n",
            "...                     ...       ...   \n",
            "20544   Sess19_impro04_F041     happy   \n",
            "20546   Sess19_impro04_F042     happy   \n",
            "20548   Sess19_impro04_M046   neutral   \n",
            "20550   Sess19_impro04_F043     happy   \n",
            "20552   Sess19_impro04_F044     happy   \n",
            "\n",
            "                                            text  \n",
            "0           어 저 지그 지금 사람 친 거야? 지금 사람 친 거 맞지? 그치?  \n",
            "2                      b/ 몰라. o/ b/ 아 몰라 어떡해. o/  \n",
            "4      아이 씨 그러니까 나 말렸어야지. 술 먹어서 운전 안 한다고 했잖아. b/  \n",
            "6                               아이 씨 괜히 운전해서 이씨.  \n",
            "8                          n/ 지섭씨. 일단 112에 신고하자.  \n",
            "...                                          ...  \n",
            "20544                 안 돼. 나 지금 너무 좋아서 이대론 못 재워.  \n",
            "20546                      여보 빨리 말해 봐. 이대로 잘 거야?  \n",
            "20548                                    아 나 잘래.  \n",
            "20550                l/ 어휴 내가 진짜 저 남자때문에 못 산다니까.  \n",
            "20552              여보 나 얼만큼 사랑한다고? 우주 별만큼? 아 여보.  \n",
            "\n",
            "[10277 rows x 3 columns]\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mecab을 이용하여 text 컬럼에 tokenize 적용"
      ],
      "metadata": {
        "id": "nD1rV86b-NKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mecab init\n",
        "mecab = Mecab()\n",
        "# 불용어 정의\n",
        "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']\n",
        "\n",
        "# text에 tokenize 적용\n",
        "df_all_txt_label['tokenized'] = df_all_txt_label['text'].apply(lambda x : mecab.morphs(str(x)))\n",
        "df_all_txt_label['tokenized'] = df_all_txt_label['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
        "\n",
        "# df_all_txt csv 파일로 저장\n",
        "df_all_txt_label.to_csv('df_all_txt.csv', mode='w', encoding=\"utf-8-sig\")\n",
        "print('==============Text 데이터 cav파일로 저장완료==============')"
      ],
      "metadata": {
        "id": "JbeY6I-76OEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bio \n",
        "\n",
        "Segment ID가 없는 row제거 후 EDA, ECG, Temp.csv파일 load"
      ],
      "metadata": {
        "id": "xjU_Zj43tJkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA 데이터 load 후 각 segment ID의 평균값 적용"
      ],
      "metadata": {
        "id": "n5bbVZVUzRh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folders=r'/content/gdrive/MyDrive/Human_understand/KEMDy19/EDA/**/*/*.csv'\n",
        "folders=glob.glob(folders)\n",
        "df_all_EDA=pd.DataFrame()\n",
        "\n",
        "for files in folders:\n",
        "    EDA=pd.read_csv(files,encoding='cp949', names=[\"EDA\", \"b\", \"c\", \"Seg\"] ,usecols=['EDA','Seg'])\n",
        "    mean_EDA=EDA.groupby('Seg')['EDA'].agg(**{'mean_EDA':'mean'}).reset_index()\n",
        "    df_all_EDA=pd.concat([df_all_EDA, mean_EDA])\n",
        "print('df_all_EDA', df_all_EDA)\n",
        "print('==============EDA 데이터 추출완료==============')\n",
        "\n",
        "# EDA csv 파일로 저장\n",
        "df_all_EDA.to_csv(\"df_all_EDA.csv\", mode='w')\n",
        "print('==============EDA 데이터 cav파일로 저장완료==============')\n",
        "\n",
        "# EDA 파일과 Label 파일 병합하기\n",
        "EDA=pd.read_csv('/content/gdrive/MyDrive/Human_understand/KEMDy19/df_all_EDA.csv',encoding='cp949')\n",
        "label= pd.read_csv('/content/gdrive/MyDrive/Human_understand/KEMDy19/df_all_label.csv', names=['Seg','Label'])\n",
        "\n",
        "# 감정 레이블에 ;(세미콜론)있는 경우 앞의 감정을 추출\n",
        "label['Label'] = label['Label'].apply(lambda x:delSemi(x))\n",
        "\n",
        "# EDA data와 label data 병합하기\n",
        "merged_EDA_label = pd.merge(EDA, label, on='Seg')"
      ],
      "metadata": {
        "id": "DakZ9CqvtcxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634e0a7d-e5be-46eb-ef10-440c87618bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      Seg  mean_EDA\n",
            "0     Sess04_impro01_F001  0.256366\n",
            "1     Sess04_impro01_F002  0.253637\n",
            "2     Sess04_impro01_F003  0.251215\n",
            "3     Sess04_impro01_F004  0.250000\n",
            "4     Sess04_impro01_F005  0.252667\n",
            "..                    ...       ...\n",
            "485  Sess11_script06_M020  5.912685\n",
            "486  Sess11_script06_M021  5.904004\n",
            "487  Sess11_script06_M022  5.929316\n",
            "488  Sess11_script06_M023  6.110741\n",
            "489  Sess11_script06_M024  6.213069\n",
            "\n",
            "[18051 rows x 2 columns]\n",
            "                                     Seg     Label\n",
            "NaN     Unnamed: 0                   Seg     Label\n",
            "0.0     1           Sess01_script01_M001  surprise\n",
            "1.0     2           Sess01_script01_F001      fear\n",
            "2.0     3           Sess01_script01_M002      fear\n",
            "3.0     4           Sess01_script01_M003      fear\n",
            "...                                  ...       ...\n",
            "20561.0 509          Sess04_impro04_M021   neutral\n",
            "20562.0 510          Sess04_impro04_F021   neutral\n",
            "20563.0 511          Sess04_impro04_F022   neutral\n",
            "20564.0 512          Sess04_impro04_F023   neutral\n",
            "20565.0 513          Sess04_impro04_F024   neutral\n",
            "\n",
            "[20567 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ECG 데이터 load 후 각 segment ID의 평균값 적용"
      ],
      "metadata": {
        "id": "mMUrmFbt0WoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folders= '/content/gdrive/MyDrive/Human_understand/KEMDy19/ECG/**/*/*.csv'\n",
        "folders=glob.glob(folders)\n",
        "df_all_ECG=pd.DataFrame()\n",
        "\n",
        "for files in folders:\n",
        "    ECG=pd.read_csv(files,encoding='cp949', names=[\"ECG\", \"b\", \"c\", \"Seg\"] ,usecols=['ECG','Seg'])\n",
        "    mean_ECG=ECG.groupby('Seg')['ECG'].agg(**{'mean_ECG':'mean'}).reset_index()\n",
        "    df_all_ECG=pd.concat([df_all_ECG, mean_ECG])\n",
        "print('df_all_ECG', df_all_ECG)\n",
        "print('==============ECG 데이터 추출완료==============')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYzQrq3RzzWO",
        "outputId": "5ecc5b06-49f7-4571-cc53-7129363c39e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      Seg  mean_ECG\n",
            "0     Sess06_impro01_F001   690.164\n",
            "1     Sess06_impro01_F002   699.592\n",
            "2     Sess06_impro01_F003   711.460\n",
            "3     Sess06_impro01_F004   717.058\n",
            "4     Sess06_impro01_F005   726.730\n",
            "..                    ...       ...\n",
            "512  Sess20_script06_M028  2999.322\n",
            "513  Sess20_script06_M029  3014.684\n",
            "514  Sess20_script06_M030  3029.000\n",
            "515  Sess20_script06_M031  3035.194\n",
            "516  Sess20_script06_M032  3039.828\n",
            "\n",
            "[18172 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temp 데이터 load후 각 segment ID의 평균값 적용"
      ],
      "metadata": {
        "id": "2R1NNtXB0kn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folders=r'/content/gdrive/MyDrive/Human_understand/KEMDy19/TEMP/**/*/*.csv'\n",
        "folders=glob.glob(folders)\n",
        "df_all_Temp=pd.DataFrame()\n",
        "\n",
        "for files in folders:\n",
        "    Temp=pd.read_csv(files,encoding='cp949', names=[\"Temp\", \"b\", \"c\", \"Seg\"] ,usecols=['Temp','Seg'])\n",
        "    mean_Temp=Temp.groupby('Seg')['Temp'].agg(**{'mean_Temp':'mean'}).reset_index()\n",
        "    df_all_Temp=pd.concat([df_all_Temp, mean_Temp])\n",
        "print('df_all_Temp', df_all_Temp)\n",
        "print('==============Temp 데이터 추출완료==============')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7JunJuz0pDX",
        "outputId": "fa6f7f7f-0d71-40e3-a04c-9bcb38078656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      Seg  mean_Temp\n",
            "0     Sess02_impro01_F001  28.770000\n",
            "1     Sess02_impro01_F002  28.770000\n",
            "2     Sess02_impro01_F003  28.765000\n",
            "3     Sess02_impro01_F004  29.173226\n",
            "4     Sess02_impro01_F005  29.132667\n",
            "..                    ...        ...\n",
            "390  Sess15_script06_M006  32.135000\n",
            "391  Sess15_script06_M007  32.278000\n",
            "392  Sess15_script06_M008  32.298696\n",
            "393  Sess15_script06_M009  32.324074\n",
            "394  Sess15_script06_M010  32.291053\n",
            "\n",
            "[18044 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_bio=pd.DataFrame()\n",
        "df_all_bio1=pd.DataFrame()\n",
        "df_all_bio2=pd.DataFrame()\n",
        "\n",
        "# EDA & ECG & Temp data 병합\n",
        "df_all_bio1 = pd.merge(merged_EDA_label, df_all_ECG, on='Seg')\n",
        "df_all_bio2 = pd.merge(df_all_Temp, df_all_bio1, on='Seg')\n",
        "\n",
        "# df_all_bio.csv 파일 저장\n",
        "df_all_bio2.to_csv(\"df_all_bio.csv\", mode='w')\n",
        "print('==============BIO 데이터 cav파일로 저장완료==============')"
      ],
      "metadata": {
        "id": "_ZbcdaR31AAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "df_all_bio.csv load후 세미콜론(;) 삭제 후 정규화 적용"
      ],
      "metadata": {
        "id": "5TmWX1o419pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_bio=pd.read_csv('/content/gdrive/MyDrive/Human_understand/KEMDy19/df_all_bio.csv', usecols=['Seg', 'mean_EDA', 'mean_ECG', 'mean_Temp', 'Label'])\n",
        "\n",
        "# 감정 레이블에 ;(세미콜론)있는 경우 앞의 감정을 추출\n",
        "df_all_bio['Label'] = df_all_bio['Label'].apply(lambda x:delSemi(x))\n",
        "\n",
        "# 0 ~ 1 사이의 값으로 정규화 세팅\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "scaled_mean_EDA=pd.read_csv(\"/content/gdrive/MyDrive/Human_understand/KEMDy19/df_all_bio.csv\",usecols=[\"mean_EDA\"])\n",
        "scaled_mean_ECG=pd.read_csv(\"/content/gdrive/MyDrive/Human_understand/KEMDy19/df_all_bio.csv\",usecols=[\"mean_ECG\"])\n",
        "scaled_mean_Temp=pd.read_csv(\"/content/gdrive/MyDrive/Human_understand/KEMDy19/df_all_bio.csv\",usecols=[\"mean_Temp\"])\n",
        "\n",
        "df_all_bio[\"mean_EDA\"]=scaler.fit_transform(scaled_mean_EDA)\n",
        "df_all_bio[\"mean_ECG\"]=scaler.fit_transform(scaled_mean_ECG)\n",
        "df_all_bio[\"mean_Temp\"]=scaler.fit_transform(scaled_mean_Temp)\n",
        "\n",
        "# 최소값을 적용하여 중복값 제거\n",
        "df_all_bio = df_all_bio.groupby('Seg').min()\n",
        "\n",
        "# scaled_df_all_bio.csv로 저장\n",
        "df_all_bio.to_csv(\"scaled_df_all_bio.csv\", mode=\"w\")\n",
        "print('==============정규화 처리한 BIO 데이터 cav파일로 저장완료==============')"
      ],
      "metadata": {
        "id": "w0LKRy4Z1n63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "scaled_df_all_bio.csv와 df_all_tex.csv를 merge하여 merged_bio_text.csv로 저장"
      ],
      "metadata": {
        "id": "lERfIpOzMmEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df_all_bio=pd.read_csv('/content/gdrive/MyDrive/Human_understand/KEMDy19/scaled_df_all_bio.csv')\n",
        "df_all_txt = pd.read_csv('/content/gdrive/MyDrive/Human_understand/KEMDy19/df_all_txt.csv', usecols=['Seg', 'tokenized'])\n",
        "\n",
        "# bio data와 text data를 병합\n",
        "merged_bio_text = pd.merge(scaled_df_all_bio, df_all_txt, on='Seg', how='left')\n",
        "\n",
        "# bio와 text가 병합된 data의 label 컬럼에 one-hot-encoding 적용 후 csv파일로 저장하기\n",
        "merged_bio_text = pd.get_dummies(merged_bio_text, columns=['Label'])\n",
        "merged_bio_text.to_csv(\"merged_bio_text.csv\", mode=\"w\", encoding='utf-8-sig')\n",
        "print('==============BIO 데이터와 Text 병합한 데이터 cav파일로 저장완료==============')"
      ],
      "metadata": {
        "id": "GH3gmzzdNUGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wav\n",
        "Wav 파일내 .wav파일들을 하나의 폴더에 담기"
      ],
      "metadata": {
        "id": "qrUwDQDesUs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targetPattern = '/content/gdrive/MyDrive/Human_understand/KEMDy19/wav/**/**/*.wav'\n",
        "allWavFile = glob.glob(targetPattern)\n",
        "\n",
        "for wav_file in allWavFile:\n",
        "    shutil.copy(wav_file, 'Your_dataset_path/Human_understand/merged_wav_folder')\n",
        "print('==============Label 데이터 추출완료==============')"
      ],
      "metadata": {
        "id": "Fbxgp_AvsAia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하나로 모인 .wav 파일 로드 및 MFCC 추출 후 .npy 파일로 저장"
      ],
      "metadata": {
        "id": "vyTWigWmCFAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folders= '/content/gdrive/MyDrive/Human_understand/merged_wav_folder/*.wav'\n",
        "folders=glob.glob(folders)\n",
        "\n",
        "# mfcc 추출시 발생되는 warning 제거하기\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "append_list=[]\n",
        "extend_list=[]\n",
        "for files in folders:\n",
        "    audio, sr = librosa.load(files, sr=16000)\n",
        "    #mfcc추출 파라미터 설정\n",
        "    mfcc = librosa.feature.mfcc(audio, sr=16000, n_mfcc=100, n_fft=400, hop_length=160) \n",
        "    #전처리 scaling\n",
        "    mfcc = sklearn.preprocessing.scale(mfcc, axis=1)\n",
        "    #데이터의 길이를 5.35초로 자르고 5.35초보다 작을 경우에만 패딩 작업\n",
        "    pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
        "    #0.46초=40,5.35초=(about)465\n",
        "    padded_mfcc = pad2d(mfcc, 465)\n",
        "    \n",
        "    append_list.append(padded_mfcc)\n",
        "    extend_list.extend(append_list)\n",
        "    append_list.clear()\n",
        "\n",
        "extend_list_array=np.array(extend_list)\n",
        "\n",
        "# mfcc가 담긴 extend_list_array를 .npy로 저장\n",
        "np.save(r'/content/gdrive/MyDrive/Human_understand/KEMDy19/all_mfcc.npy', extend_list_array)\n",
        "print('==============MFCC 데이터 npy파일로 저장완료==============')"
      ],
      "metadata": {
        "id": "LmrH2vGW6Gqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "wav파일의 segment ID값을 저장하기 위해 all_wavSeg.txt 파일 생성\n",
        "1. 생성한 mfcc(all_mfcc.npy)파일에는 segment ID가 없으므로 추후 감정label 추출을 위해 segment ID가 필요함\n",
        "\n",
        "2. wav 파일을 기준으로 mfcc를 생성했기 때문에,\n",
        "해당 파일의 이름이 segment ID라는 점을 고려하여 wav file 이름을 추출함"
      ],
      "metadata": {
        "id": "qMC8q0RMW_Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 해당 부분은 코랩에서 실행시 순서대로 파일들을 읽어오지 않아 Segment ID가 랜덤으로 작성될 우려가 있으므로\n",
        "# preprocessing_data.py를 이용하여 해당 부분만 실행시킬 것을 권장드림\n",
        "\n",
        "# targetPattern = '/content/gdrive/MyDrive/Human_understand/KEMDy19/wav/**/**/*.wav'\n",
        "allTextFile = glob.glob(targetPattern)\n",
        "\n",
        "# wav 파일구성 순서대로 segment ID를 추출하여 하나의 text파일에 입력\n",
        "mergedText = open('all_wavSeg.txt', 'w', encoding=\"UTF-8\")\n",
        "\n",
        "for i in range(len(allTextFile)):\n",
        "    myText = allTextFile[i]\n",
        "    first = myText.rfind('Sess')\n",
        "    last = myText.find('.wav')\n",
        "    sessID = myText[first:last]\n",
        "    myText = open(myText, 'r', encoding=\"UTF-8\")\n",
        "    text = sessID + ',' + '\\n'\n",
        "    mergedText.write(text)\n",
        "mergedText.close()\n",
        "print('==============WAV Segment ID 데이터 추출완료==============')"
      ],
      "metadata": {
        "id": "By0QFktiVmv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wav segment ID와 Label data를 read한 후 병합하기\n",
        "all_wavSeg = pd.read_csv('/content/gdrive/MyDrive/Human_understand/KEMDy19/all_wavSeg.txt', names=['Seg', 'a'])\n",
        "label= pd.read_csv('/content/gdrive/MyDrive/Human_understand/KEMDy19/df_all_label.csv')\n",
        "allwav = pd.merge(all_wavSeg, label, on='Seg', how='left')\n",
        "\n",
        "# 병합된 wav segment ID와 Label data를 csv로 저장\n",
        "allwav.to_csv(\"allwav.csv\", mode=\"w\")\n",
        "print('==============병합한 WAV Segment ID 데이터와 Lable 데이터 저장완료==============')"
      ],
      "metadata": {
        "id": "xIuBwOzjeJtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결측값을 제거하기 위해 bio['seg']를 기준으로 데이터 취합"
      ],
      "metadata": {
        "id": "3jEPXcOMO93o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merged_bio_text.csv를 read\n",
        "bio_seg=pd.read_csv('/content/gdrive/MyDrive/Human_understand/KEMDy19/merged_bio_text.csv', usecols=[\"Seg\"])\n",
        "\n",
        "# all_wavSeg 파일 read후 list로 변형\n",
        "wav_seg=pd.read_csv(\"/content/gdrive/MyDrive/Human_understand/KEMDy19/all_wavSeg.txt\",names=['Seg'])\n",
        "wav_seg_list=wav_seg[\"Seg\"].to_list()\n",
        "\n",
        "# bio의 segment ID를 wav_seg_list에서 찾고 해당 index를 mfcc_index 리스트에 저장 \n",
        "mfcc_index=[]\n",
        "for i in range(len(bio_seg)):\n",
        "    #search에 segID 들어감\n",
        "    search=bio_seg.loc[i,['Seg']].values \n",
        "    if search in wav_seg_list:\n",
        "        mfcc_index.append(wav_seg_list.index(search))\n",
        "str(mfcc_index)"
      ],
      "metadata": {
        "id": "rhp38i9w6GmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mfcc_index 리스트에 저장된 index를 기준으로  \n",
        "# 앞서 생성한 all_mfcc에서 해당 index의 mfcc를 추출하여 needed mfcc에 저장\n",
        "\n",
        "all_mfcc = np.load('/content/gdrive/MyDrive/Human_understand/all_mfcc.npy')\n",
        "all_mfcc.tolist()\n",
        "\n",
        "needed_mfcc=[]\n",
        "for i in mfcc_index:\n",
        "    needed_mfcc.append(all_mfcc[i])\n",
        "needed_mfcc_array=np.array(needed_mfcc)\n",
        "np.save(r'Your_dataset_path/Human_understand/needed_mfcc.npy', needed_mfcc_array)\n",
        "print('==============추출한 인덱스를 통해 필요한 MFCC 데이터를 뽑은 후 npy파일로 저장==============')"
      ],
      "metadata": {
        "id": "6a_4SutW6GoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y데이터(정답 데이터) 생성\n",
        "mfcc_y = pd.read_csv(r'C:/Users/user/Downloads/KEMDy19/allwav.csv', usecols=[\"Label\"])\n",
        "needed_mfcc_y=[]\n",
        "for i in mfcc_index:\n",
        "    needed_mfcc_y.append(mfcc_y.loc[i,['Label']].values) "
      ],
      "metadata": {
        "id": "9IXxZuijWb2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle file로 저장\n",
        "with open('needed_mfcc_y.pkl','wb') as f:\n",
        "    pickle.dump(needed_mfcc_y, f)\n",
        "print('==============MFCC 데이터와 매칭되는 label 데이터 pickle파일로 저장완료==============')"
      ],
      "metadata": {
        "id": "X4S_kF24h0Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oXgp72Xb9nsS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}